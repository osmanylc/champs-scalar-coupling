{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../modules/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from preprocess import (load_data, encode_labels, \n",
    "                        split_validation, count_atoms, \n",
    "                        add_atom_count, add_distance, \n",
    "                        center_cos, center_d,\n",
    "                        decode_labels)\n",
    "from predict import eval_metric, predict_hgbr\n",
    "from features import distance\n",
    "from data_loading import load_data as ld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test, coords = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = split_validation(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GB Inference Model (GBR, XGB, LGB, HGBR)\n",
    "\n",
    "Starting with HGBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_hat = predict_hgbr(x_train, y_train, x_val)\n",
    "\n",
    "eval_metric(y_val, y_val_hat, x_val.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = distance(train)\n",
    "train_d = train.assign(d=d)\n",
    "\n",
    "x_d_train, x_d_val, y_train, y_val = split_validation(train_d)\n",
    "y_d_val_hat = predict_hgbr(x_d_train, y_train, x_d_val)\n",
    "\n",
    "eval_metric(y_val, y_d_val_hat, x_d_val.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center Molecule Coords\n",
    "\n",
    "- [x] Find center of molecule by averaging atom positions\n",
    "- [x] Subtract centroid coords from molecule coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, coords = load_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dc = train.assign(d=d)\n",
    "\n",
    "x_dc_train, x_dc_val, y_train, y_val = split_validation(train_dc)\n",
    "y_dc_val_hat = predict_hgbr(x_dc_train, y_train, x_dc_val)\n",
    "\n",
    "eval_metric(y_val, y_dc_val_hat, x_dc_val.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_freqs = count_atoms(coords)\n",
    "atom_freqs.head()\n",
    "\n",
    "train_af = train_dc.merge(atom_freqs, how='left', on='molecule_name')\n",
    "train_af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_af_train, x_af_val, y_af_train, y_af_val = split_validation(train_af)\n",
    "y_af_hat = predict_hgbr(x_af_train, y_af_train, x_af_val)\n",
    "\n",
    "eval_metric(y_af_val, y_af_hat, x_af_val.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_af_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lgb_train = encode_labels(x_af_train)\n",
    "x_lgb_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lgb = lgb.Dataset(x_lgb_train, label=y_af_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective': 'mae', 'num_leaves': 63}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.train(param, train_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lgb_val = encode_labels(x_af_val)\n",
    "y_lgb_hat = bst.predict(x_lgb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(y_af_val, y_lgb_hat, x_lgb_val.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_af = test.merge(atom_freqs, how='left', on='molecule_name')\n",
    "test_af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_af = test_af.assign(d=distance(test_af))\n",
    "test_af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lgb = encode_labels(test_af)\n",
    "test_lgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = bst.predict(test_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub.scalar_coupling_constant = y_hat\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub.to_csv('lgb_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features w.r.t. Centroid\n",
    "\n",
    "- [x] Find angle between atoms w.r.t. centroid\n",
    "- [x] Distance to centroid and to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecule-related Features\n",
    "\n",
    "- [x] Frequency of each atom in molecule\n",
    "- [ ] Size of molecule (x,y,z)\n",
    "- [ ] Weight of molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecule Graph Features\n",
    "\n",
    "- [ ] Use software to infer molecular bonds.\n",
    "- [ ] Number and types of bonds between atoms.\n",
    "- [ ] Can find dipole moments, potential energy, magnetic shielding tensor from this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Preprocess Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for data transformation:\n",
    "\n",
    "1. [x] Coordinates from structures.csv\n",
    "2. [x] Encode types into numerical labels.\n",
    "3. [x] Encode molecule atoms into columns with atom counts.\n",
    "4. [x] Center molecule coordinates.\n",
    "5. [x] Add angle w.r.t. centroid feature. (cos of angle is good enough)\n",
    "6. Add angle w.r.t. nearest atom feature.\n",
    "7. [x] Add distance feature.\n",
    "8. Add columns of bond orders btw atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test, coords = ld()\n",
    "train, test, encs = encode_labels(train, test)\n",
    "train, test = add_atom_count(train, test, coords)\n",
    "train, test = add_distance(train, test)\n",
    "train, test = center_cos(train, test)\n",
    "train, test = center_d(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = (train.drop(columns='molecule_name'), test.drop(columns='molecule_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lightgbm for prediction\n",
    "import lightgbm as lgb\n",
    "\n",
    "x_t, x_v, y_t, y_v = split_validation(train)\n",
    "train_lgb = lgb.Dataset(x_t, label=y_t)\n",
    "param = {'objective': 'mae', 'num_leaves': 200}\n",
    "\n",
    "h = lgb.train(param, train_lgb)\n",
    "y_v_hat = h.predict(x_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v = decode_labels(x_v, encs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_by_type(y, y_hat, j_type):\n",
    "    maes = (y_hat - y).abs().groupby(j_type).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, 1e-9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_by_type(y_v, y_v_hat, x_v.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v.reset_index().groupby('type')['index'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(y_v, y_v_hat, x_v.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = h.predict(test)\n",
    "sub = pd.read_csv('../data/sample_submission.csv')\n",
    "sub.loc[:, 'scalar_coupling_constant'] = y_hat\n",
    "sub.to_csv('../data/lgb_sub_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Diffrent Hypothesis for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_mean = []\n",
    "for jtype, grp in train.groupby('type'):\n",
    "    x_t, x_v, y_t, y_v = split_validation(grp)\n",
    "    train_lgb = lgb.Dataset(x_t, label=y_t)\n",
    "    param = {'objective': 'mae', 'num_leaves': 200, 'num_iterations': 500}\n",
    "\n",
    "    h = lgb.train(param, train_lgb)\n",
    "    y_v_hat = h.predict(x_v)\n",
    "    \n",
    "    maes = np.log((y_v_hat - y_v).abs().mean())\n",
    "    maes_mean.append(maes)\n",
    "    print(f'Type: {jtype}; Loss: {maes}')\n",
    "print(f'Metric: {np.mean(maes_mean)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats = []\n",
    "\n",
    "for jtype in train.type.unique():\n",
    "    train_j = train.loc[train.type == jtype]\n",
    "    test_j = test.loc[test.type == jtype]\n",
    "    \n",
    "    y_t = train_j.scalar_coupling_constant\n",
    "    x_t = train_j.drop(columns='scalar_coupling_constant')\n",
    "    \n",
    "    train_lgb = lgb.Dataset(x_t, label=y_t)\n",
    "    param = {'objective': 'mae', 'num_leaves': 200, 'num_iterations': 500}\n",
    "    \n",
    "    h = lgb.train(param, train_lgb)\n",
    "    y_hats.append(test_j.assign(y_hat=h.predict(test_j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = pd.concat(y_hats).sort_values('id')[['id', 'y_hat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')\n",
    "sub.loc[:, 'scalar_coupling_constant'] = y_hat.y_hat\n",
    "sub.to_csv('../data/lgb_sub_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- [x] Fix data loading paths.\n",
    "- [ ] Implement K-Fold cross-validation. \n",
    "- [ ] Add features from artgor kernel.\n",
    "- [ ] Add angle feature from the other kernel\n",
    "- [x] Divide the dataset into the different J-coupling types and check the error in each.\n",
    "- [x] Keep Label Encoder so we can reverse mappings\n",
    "- [ ] Optimize hyperparams in LightGBM. Try using XGBoost.\n",
    "- [x] Fix bond.csv and atom.csv indices by making them start at 0.\n",
    "- [ ] Use bond type and charge features.\n",
    "- [ ] Create more features from the bond type and charge.\n",
    "- [ ] Try predicting some of the auxillary data (like Mulliken charges)\n",
    "- [ ] Reverse label encodings so we can analyze outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train, test, coords = ld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col='id')\n",
    "bonds = pd.read_csv('../data/bonds.csv')\n",
    "atoms = pd.read_csv('../data/atoms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = train.rename(columns={'atom_index_0': 'a0',\n",
    "        'atom_index_1': 'a1'})\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.merge(base_df, atoms, how='left',\n",
    "        left_on=['molecule_name', 'a0'],\n",
    "        right_on=['molecule', 'atom_index'])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.merge(data_df, atoms, how='left',\n",
    "        left_on=['molecule_name', 'a1'],\n",
    "        right_on=['molecule', 'atom_index'],\n",
    "        suffixes=('_0', '_1'))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns=['a0', 'a1'], inplace=True)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(data_df, bonds, how='left',\n",
    "        left_on=['molecule_name', 'atom_index_0', 'atom_index_1'],\n",
    "        right_on=['molecule', 'atom_0', 'atom_1']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
