{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../modules/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from preprocess import (load_data, encode_labels, \n",
    "                        split_validation, count_atoms, \n",
    "                        add_atom_count, add_distance, \n",
    "                        center_cos, center_d,\n",
    "                        decode_labels)\n",
    "from predict import eval_metric, predict_hgbr\n",
    "from features import distance\n",
    "from data_loading import load_data as ld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test, coords = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = split_validation(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GB Inference Model (GBR, XGB, LGB, HGBR)\n",
    "\n",
    "Starting with HGBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_hat = predict_hgbr(x_train, y_train, x_val)\n",
    "\n",
    "eval_metric(y_val, y_val_hat, x_val.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = distance(train)\n",
    "train_d = train.assign(d=d)\n",
    "\n",
    "x_d_train, x_d_val, y_train, y_val = split_validation(train_d)\n",
    "y_d_val_hat = predict_hgbr(x_d_train, y_train, x_d_val)\n",
    "\n",
    "eval_metric(y_val, y_d_val_hat, x_d_val.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center Molecule Coords\n",
    "\n",
    "- [x] Find center of molecule by averaging atom positions\n",
    "- [x] Subtract centroid coords from molecule coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, coords = load_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dc = train.assign(d=d)\n",
    "\n",
    "x_dc_train, x_dc_val, y_train, y_val = split_validation(train_dc)\n",
    "y_dc_val_hat = predict_hgbr(x_dc_train, y_train, x_dc_val)\n",
    "\n",
    "eval_metric(y_val, y_dc_val_hat, x_dc_val.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_freqs = count_atoms(coords)\n",
    "atom_freqs.head()\n",
    "\n",
    "train_af = train_dc.merge(atom_freqs, how='left', on='molecule_name')\n",
    "train_af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_af_train, x_af_val, y_af_train, y_af_val = split_validation(train_af)\n",
    "y_af_hat = predict_hgbr(x_af_train, y_af_train, x_af_val)\n",
    "\n",
    "eval_metric(y_af_val, y_af_hat, x_af_val.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_af_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lgb_train = encode_labels(x_af_train)\n",
    "x_lgb_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lgb = lgb.Dataset(x_lgb_train, label=y_af_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective': 'mae', 'num_leaves': 63}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.train(param, train_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lgb_val = encode_labels(x_af_val)\n",
    "y_lgb_hat = bst.predict(x_lgb_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(y_af_val, y_lgb_hat, x_lgb_val.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_af = test.merge(atom_freqs, how='left', on='molecule_name')\n",
    "test_af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_af = test_af.assign(d=distance(test_af))\n",
    "test_af.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lgb = encode_labels(test_af)\n",
    "test_lgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = bst.predict(test_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub.scalar_coupling_constant = y_hat\n",
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub.to_csv('lgb_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features w.r.t. Centroid\n",
    "\n",
    "- [x] Find angle between atoms w.r.t. centroid\n",
    "- [x] Distance to centroid and to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecule-related Features\n",
    "\n",
    "- [x] Frequency of each atom in molecule\n",
    "- [ ] Size of molecule (x,y,z)\n",
    "- [ ] Weight of molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecule Graph Features\n",
    "\n",
    "- [x] Use software to infer molecular bonds.\n",
    "- [ ] Number and types of bonds between atoms.\n",
    "- [ ] Can find dipole moments, potential energy, magnetic shielding tensor from this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Preprocess Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for data transformation:\n",
    "\n",
    "1. [x] Coordinates from structures.csv\n",
    "2. [x] Encode types into numerical labels.\n",
    "3. [x] Encode molecule atoms into columns with atom counts.\n",
    "4. [x] Center molecule coordinates.\n",
    "5. [x] Add angle w.r.t. centroid feature. (cos of angle is good enough)\n",
    "6. Add angle w.r.t. nearest atom feature.\n",
    "7. [x] Add distance feature.\n",
    "8. Add columns of bond orders btw atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test, coords = ld()\n",
    "train, test, encs = encode_labels(train, test)\n",
    "train, test = add_atom_count(train, test, coords)\n",
    "train, test = add_distance(train, test)\n",
    "train, test = center_cos(train, test)\n",
    "train, test = center_d(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = (train.drop(columns='molecule_name'), test.drop(columns='molecule_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lightgbm for prediction\n",
    "import lightgbm as lgb\n",
    "\n",
    "x_t, x_v, y_t, y_v = split_validation(train)\n",
    "train_lgb = lgb.Dataset(x_t, label=y_t)\n",
    "param = {'objective': 'mae', 'num_leaves': 200}\n",
    "\n",
    "h = lgb.train(param, train_lgb)\n",
    "y_v_hat = h.predict(x_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v = decode_labels(x_v, encs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_by_type(y, y_hat, j_type):\n",
    "    maes = (y_hat - y).abs().groupby(j_type).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, 1e-9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_by_type(y_v, y_v_hat, x_v.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_v.reset_index().groupby('type')['index'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(y_v, y_v_hat, x_v.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = h.predict(test)\n",
    "sub = pd.read_csv('../data/sample_submission.csv')\n",
    "sub.loc[:, 'scalar_coupling_constant'] = y_hat\n",
    "sub.to_csv('../data/lgb_sub_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Diffrent Hypothesis for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_mean = []\n",
    "for jtype, grp in train.groupby('type'):\n",
    "    x_t, x_v, y_t, y_v = split_validation(grp)\n",
    "    train_lgb = lgb.Dataset(x_t, label=y_t)\n",
    "    param = {'objective': 'mae', 'num_leaves': 200, 'num_iterations': 500}\n",
    "\n",
    "    h = lgb.train(param, train_lgb)\n",
    "    y_v_hat = h.predict(x_v)\n",
    "    \n",
    "    maes = np.log((y_v_hat - y_v).abs().mean())\n",
    "    maes_mean.append(maes)\n",
    "    print(f'Type: {jtype}; Loss: {maes}')\n",
    "print(f'Metric: {np.mean(maes_mean)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats = []\n",
    "\n",
    "for jtype in train.type.unique():\n",
    "    train_j = train.loc[train.type == jtype]\n",
    "    test_j = test.loc[test.type == jtype]\n",
    "    \n",
    "    y_t = train_j.scalar_coupling_constant\n",
    "    x_t = train_j.drop(columns='scalar_coupling_constant')\n",
    "    \n",
    "    train_lgb = lgb.Dataset(x_t, label=y_t)\n",
    "    param = {'objective': 'mae', 'num_leaves': 200, 'num_iterations': 500}\n",
    "    \n",
    "    h = lgb.train(param, train_lgb)\n",
    "    y_hats.append(test_j.assign(y_hat=h.predict(test_j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = pd.concat(y_hats).sort_values('id')[['id', 'y_hat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')\n",
    "sub.loc[:, 'scalar_coupling_constant'] = y_hat.y_hat\n",
    "sub.to_csv('../data/lgb_sub_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- [x] Fix data loading paths.\n",
    "- [ ] Pickle DataFrames to improve loading times.\n",
    "- [ ] Implement K-Fold cross-validation. \n",
    "- [ ] Add features from artgor kernel.\n",
    "- [ ] Add angle feature from the other kernel\n",
    "- [x] Divide the dataset into the different J-coupling types and check the error in each.\n",
    "- [x] Keep Label Encoder so we can reverse mappings\n",
    "- [ ] Optimize hyperparams in LightGBM. Try using XGBoost.\n",
    "- [x] Fix bond.csv and atom.csv indices by making them start at 0.\n",
    "- [ ] Use bond type and charge features.\n",
    "- [ ] Create more features from the bond type and charge.\n",
    "- [ ] Try predicting some of the auxillary data (like Mulliken charges)\n",
    "- [ ] Reverse label encodings so we can analyze outputs.\n",
    "- [ ] Want to make diagnostic tools:\n",
    "    - [ ] How much is each feature contributing?\n",
    "    - [ ] Which hyperparameters are best? Which hyperparameters do we choose to search over.\n",
    "    - [ ] Which CV scheme do we use?\n",
    "    - [ ] How do we integrate out of fold features from the extra data?\n",
    "    - [ ] How do we set up a neural net?\n",
    "    - [ ] What features are important in the real calculations?\n",
    "    - [ ] What are the margnetic shielding tensors?\n",
    "    - [ ] Look at intro to chem stuff for atomic properties we could add.\n",
    "    - [ ] What is the relationship between each feature and the target variable?\n",
    "    - [ ] What about feature pairs and the target variable? Any clear trends showing up?\n",
    "    - [ ] Do things look as expected in the plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train, test, coords = ld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col='id')\n",
    "bonds = pd.read_csv('../data/bonds.csv')\n",
    "atoms = pd.read_csv('../data/atoms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molecule sizes features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = atoms.groupby('molecule')[['x', 'y', 'z']]\n",
    "dists = grp.max() - grp.min()\n",
    "dists.columns = ['x_range', 'y_range', 'z_range']\n",
    "dists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path from atom 0 to atom 1\n",
    "\n",
    "- [ ] Use BFS from `atom_0` to `atom_1`\n",
    "    - [ ] Make adjacency list / matrix of one molecule's atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_bonds = bonds.loc[bonds.loc[:, 'molecule'] == 'dsgdb9nsd_077199']\n",
    "m_bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.zeros(2 * (len(m_bonds),), dtype=np.uint8)\n",
    "\n",
    "for _, row in m_bonds.iterrows():\n",
    "    i,j,v = row['atom_0'], row['atom_1'], row['bond_type']\n",
    "    adj[i,j] = v\n",
    "    adj[j,i] = v\n",
    "\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_d = dict()\n",
    "for i in range(len(m_bonds)):\n",
    "    adj_d[i] = []\n",
    "\n",
    "for _, row in m_bonds.iterrows():\n",
    "    i,j= row['atom_0'], row['atom_1']\n",
    "    adj_d[i].append(j)\n",
    "    adj_d[j].append(i)\n",
    "\n",
    "adj_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bond Path Between Atoms\n",
    "\n",
    "Given `atom_index_0`, `atom_index_1`, and `adj_d`, find the bonds between the atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def find_bond_path(adj_d, a0, a1):\n",
    "    q = deque([a0])\n",
    "    visited = {a0: None}\n",
    "    \n",
    "    while len(q) > 0:\n",
    "        node = q.popleft()\n",
    "        adjs = filter(lambda x: x not in visited, adj_d[node])\n",
    "        \n",
    "        for adj in adjs:\n",
    "            visited[adj] = node\n",
    "            q.append(adj)\n",
    "            \n",
    "            if adj == a1:\n",
    "                path = []\n",
    "                curr_node = a1\n",
    "                while curr_node is not None:\n",
    "                    path.append(curr_node)\n",
    "                    curr_node = visited[curr_node]\n",
    "                return list(reversed(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_bond_path(adj_d, 5, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
